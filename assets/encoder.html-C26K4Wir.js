import{_ as n}from"./plugin-vue_export-helper-DlAUqK2U.js";import{o as s,c as a,e as t}from"./app-p8FhccK8.js";const p={},o=t(`<h2 id="encoder" tabindex="-1"><a class="header-anchor" href="#encoder"><span>Encoder</span></a></h2><figure><img src="http://47.94.135.15:81/Transformer/Encoder-Layer.webp" alt="Encoder-Layer" tabindex="0"><figcaption>Encoder-Layer</figcaption></figure><h3 id="code-example" tabindex="-1"><a class="header-anchor" href="#code-example"><span>Code Example</span></a></h3><div class="language-python line-numbers-mode" data-ext="py" data-title="EncoderLayer"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">EncoderLayer</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;
    Single encoder layer in a transformer encoder.

    Performs multi-head attention and position-wise feedforward operations.
    Supports layer normalization before or after these operations.

    Args:
        d_model (int): Embedding dimension size.
        ffn_hidden (int): Feedforward network hidden layer size.
        n_head (int): Number of attention heads.
        drop_prob (float): Dropout probability.
        norm_type (str): Type of layer normalization, &#39;pre&#39; or &#39;post&#39;.
        pe (str): Positional encoding type, &#39;rotary&#39;, &#39;relative&#39; or &#39;absolute&#39;.

    &quot;&quot;&quot;</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> d_model<span class="token punctuation">,</span> ffn_hidden<span class="token punctuation">,</span> n_head<span class="token punctuation">,</span> drop_prob<span class="token punctuation">,</span> norm_type<span class="token punctuation">,</span> pe<span class="token operator">=</span><span class="token string">&#39;absolute&#39;</span><span class="token punctuation">,</span> norm_bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span>
                 <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
        <span class="token keyword">assert</span> norm_type <span class="token keyword">in</span> <span class="token punctuation">(</span><span class="token string">&#39;pre&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;post&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;rezero&#39;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> \\
            <span class="token string">&quot;norm_type must be &#39;pre&#39;, &#39;post&#39; or &#39;rezero&#39;&quot;</span>
        <span class="token keyword">assert</span> pe <span class="token keyword">in</span> <span class="token punctuation">(</span>
            <span class="token string">&#39;rotary&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;relative&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;absolute&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;none&#39;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">&quot;rpe must be either &#39;rotary&#39; or &#39;relative&#39; or &#39;absolute&#39;&quot;</span>
        <span class="token keyword">if</span> pe <span class="token operator">==</span> <span class="token string">&#39;rotary&#39;</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>attention <span class="token operator">=</span> MultiHeadAttention<span class="token punctuation">(</span>d_model<span class="token operator">=</span>d_model<span class="token punctuation">,</span> n_head<span class="token operator">=</span>n_head<span class="token punctuation">)</span>
        <span class="token keyword">elif</span> pe <span class="token operator">==</span> <span class="token string">&#39;relative&#39;</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>attention <span class="token operator">=</span> RPEMultiHeadAttention<span class="token punctuation">(</span>d_model<span class="token operator">=</span>d_model<span class="token punctuation">,</span> n_head<span class="token operator">=</span>n_head<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>attention <span class="token operator">=</span> MultiHeadAttention<span class="token punctuation">(</span>d_model<span class="token operator">=</span>d_model<span class="token punctuation">,</span> n_head<span class="token operator">=</span>n_head<span class="token punctuation">,</span> pe<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dropout1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>p<span class="token operator">=</span>drop_prob<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>ffn <span class="token operator">=</span> PositionWiseFeedForward<span class="token punctuation">(</span>d_model<span class="token operator">=</span>d_model<span class="token punctuation">,</span> hidden<span class="token operator">=</span>ffn_hidden<span class="token punctuation">,</span> drop_prob<span class="token operator">=</span>drop_prob<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dropout2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>p<span class="token operator">=</span>drop_prob<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>norm_type <span class="token operator">=</span> norm_type  <span class="token comment"># post, pre, or rezero</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>norm_type <span class="token operator">==</span> <span class="token string">&#39;pre&#39;</span> <span class="token keyword">or</span> self<span class="token punctuation">.</span>norm_type <span class="token operator">==</span> <span class="token string">&#39;post&#39;</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>norm1 <span class="token operator">=</span> LayerNorm<span class="token punctuation">(</span>d_model<span class="token operator">=</span>d_model<span class="token punctuation">,</span> bias<span class="token operator">=</span>norm_bias<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>norm2 <span class="token operator">=</span> LayerNorm<span class="token punctuation">(</span>d_model<span class="token operator">=</span>d_model<span class="token punctuation">,</span> bias<span class="token operator">=</span>norm_bias<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>res_weight <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> src_mask<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>norm_type <span class="token operator">==</span> <span class="token string">&#39;post&#39;</span><span class="token punctuation">:</span>
            x <span class="token operator">=</span> self<span class="token punctuation">.</span>norm1<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dropout1<span class="token punctuation">(</span>self<span class="token punctuation">.</span>attention<span class="token punctuation">(</span>query<span class="token operator">=</span>x<span class="token punctuation">,</span> key<span class="token operator">=</span>x<span class="token punctuation">,</span> value<span class="token operator">=</span>x<span class="token punctuation">,</span> mask<span class="token operator">=</span>src_mask<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> x<span class="token punctuation">)</span>
            x <span class="token operator">=</span> self<span class="token punctuation">.</span>norm2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dropout2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>ffn<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> x<span class="token punctuation">)</span>
        <span class="token keyword">elif</span> self<span class="token punctuation">.</span>norm_type <span class="token operator">==</span> <span class="token string">&#39;pre&#39;</span><span class="token punctuation">:</span>
            x_pre_norm <span class="token operator">=</span> self<span class="token punctuation">.</span>norm1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
            x <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout1<span class="token punctuation">(</span>self<span class="token punctuation">.</span>attention<span class="token punctuation">(</span>query<span class="token operator">=</span>x_pre_norm<span class="token punctuation">,</span> key<span class="token operator">=</span>x_pre_norm<span class="token punctuation">,</span> value<span class="token operator">=</span>x_pre_norm<span class="token punctuation">,</span> mask<span class="token operator">=</span>src_mask<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> x
            x <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>ffn<span class="token punctuation">(</span>self<span class="token punctuation">.</span>norm2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> x
            <span class="token comment"># x = self.attention(query=x_pre_norm, key=x_pre_norm, value=x_pre_norm, mask=src_mask) + x</span>
            <span class="token comment"># x = self.ffn(self.norm2(x)) + x</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            x <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout1<span class="token punctuation">(</span>self<span class="token punctuation">.</span>attention<span class="token punctuation">(</span>query<span class="token operator">=</span>x<span class="token punctuation">,</span> key<span class="token operator">=</span>x<span class="token punctuation">,</span> value<span class="token operator">=</span>x<span class="token punctuation">,</span> mask<span class="token operator">=</span>src_mask<span class="token punctuation">)</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>res_weight<span class="token punctuation">)</span> <span class="token operator">+</span> x
            x <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>ffn<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>res_weight<span class="token punctuation">)</span> <span class="token operator">+</span> x
        <span class="token keyword">return</span> x
        <span class="token comment"># 输出给encoder的x的shape（batch_size,seq_len,embed_size）</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,4),e=[o];function c(l,r){return s(),a("div",null,e)}const k=n(p,[["render",c],["__file","encoder.html.vue"]]),d=JSON.parse(`{"path":"/neural-network/transformer/encoder.html","title":"Encoder层介绍","lang":"zh-CN","frontmatter":{"title":"Encoder层介绍","category":"Transformer","description":"Encoder Encoder-LayerEncoder-Layer Code Example","head":[["meta",{"property":"og:url","content":"https://javaguide.cn/learning/neural-network/transformer/encoder.html"}],["meta",{"property":"og:site_name","content":"Mua'dib Guide "}],["meta",{"property":"og:title","content":"Encoder层介绍"}],["meta",{"property":"og:description","content":"Encoder Encoder-LayerEncoder-Layer Code Example"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"http://47.94.135.15:81/Transformer/Encoder-Layer.webp"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-09-02T14:03:43.000Z"}],["meta",{"property":"article:author","content":"Guide"}],["meta",{"property":"article:modified_time","content":"2024-09-02T14:03:43.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Encoder层介绍\\",\\"image\\":[\\"http://47.94.135.15:81/Transformer/Encoder-Layer.webp\\"],\\"dateModified\\":\\"2024-09-02T14:03:43.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Guide\\",\\"url\\":\\"https://javaguide.cn/article/\\"}]}"]]},"headers":[{"level":2,"title":"Encoder","slug":"encoder","link":"#encoder","children":[{"level":3,"title":"Code Example","slug":"code-example","link":"#code-example","children":[]}]}],"git":{"createdTime":1725285823000,"updatedTime":1725285823000,"contributors":[{"name":"tonygong","email":"280880907@163.com","commits":1}]},"readingTime":{"minutes":1.03,"words":310},"filePathRelative":"neural-network/transformer/encoder.md","localizedDate":"2024年9月2日","excerpt":"<h2>Encoder</h2>\\n<figure><img src=\\"http://47.94.135.15:81/Transformer/Encoder-Layer.webp\\" alt=\\"Encoder-Layer\\" tabindex=\\"0\\"><figcaption>Encoder-Layer</figcaption></figure>\\n<h3>Code Example</h3>\\n<div class=\\"language-python\\" data-ext=\\"py\\" data-title=\\"EncoderLayer\\"><pre class=\\"language-python\\"><code><span class=\\"token keyword\\">class</span> <span class=\\"token class-name\\">EncoderLayer</span><span class=\\"token punctuation\\">(</span>nn<span class=\\"token punctuation\\">.</span>Module<span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">:</span>\\n    <span class=\\"token triple-quoted-string string\\">\\"\\"\\"\\n    Single encoder layer in a transformer encoder.\\n\\n    Performs multi-head attention and position-wise feedforward operations.\\n    Supports layer normalization before or after these operations.\\n\\n    Args:\\n        d_model (int): Embedding dimension size.\\n        ffn_hidden (int): Feedforward network hidden layer size.\\n        n_head (int): Number of attention heads.\\n        drop_prob (float): Dropout probability.\\n        norm_type (str): Type of layer normalization, 'pre' or 'post'.\\n        pe (str): Positional encoding type, 'rotary', 'relative' or 'absolute'.\\n\\n    \\"\\"\\"</span>\\n\\n    <span class=\\"token keyword\\">def</span> <span class=\\"token function\\">__init__</span><span class=\\"token punctuation\\">(</span>self<span class=\\"token punctuation\\">,</span> d_model<span class=\\"token punctuation\\">,</span> ffn_hidden<span class=\\"token punctuation\\">,</span> n_head<span class=\\"token punctuation\\">,</span> drop_prob<span class=\\"token punctuation\\">,</span> norm_type<span class=\\"token punctuation\\">,</span> pe<span class=\\"token operator\\">=</span><span class=\\"token string\\">'absolute'</span><span class=\\"token punctuation\\">,</span> norm_bias<span class=\\"token operator\\">=</span><span class=\\"token boolean\\">True</span><span class=\\"token punctuation\\">,</span> <span class=\\"token operator\\">*</span>args<span class=\\"token punctuation\\">,</span>\\n                 <span class=\\"token operator\\">**</span>kwargs<span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">:</span>\\n        <span class=\\"token builtin\\">super</span><span class=\\"token punctuation\\">(</span><span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">.</span>__init__<span class=\\"token punctuation\\">(</span><span class=\\"token operator\\">*</span>args<span class=\\"token punctuation\\">,</span> <span class=\\"token operator\\">**</span>kwargs<span class=\\"token punctuation\\">)</span>\\n        <span class=\\"token keyword\\">assert</span> norm_type <span class=\\"token keyword\\">in</span> <span class=\\"token punctuation\\">(</span><span class=\\"token string\\">'pre'</span><span class=\\"token punctuation\\">,</span> <span class=\\"token string\\">'post'</span><span class=\\"token punctuation\\">,</span> <span class=\\"token string\\">'rezero'</span><span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">,</span> \\\\\\n            <span class=\\"token string\\">\\"norm_type must be 'pre', 'post' or 'rezero'\\"</span>\\n        <span class=\\"token keyword\\">assert</span> pe <span class=\\"token keyword\\">in</span> <span class=\\"token punctuation\\">(</span>\\n            <span class=\\"token string\\">'rotary'</span><span class=\\"token punctuation\\">,</span> <span class=\\"token string\\">'relative'</span><span class=\\"token punctuation\\">,</span> <span class=\\"token string\\">'absolute'</span><span class=\\"token punctuation\\">,</span> <span class=\\"token string\\">'none'</span><span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">,</span> <span class=\\"token string\\">\\"rpe must be either 'rotary' or 'relative' or 'absolute'\\"</span>\\n        <span class=\\"token keyword\\">if</span> pe <span class=\\"token operator\\">==</span> <span class=\\"token string\\">'rotary'</span><span class=\\"token punctuation\\">:</span>\\n            self<span class=\\"token punctuation\\">.</span>attention <span class=\\"token operator\\">=</span> MultiHeadAttention<span class=\\"token punctuation\\">(</span>d_model<span class=\\"token operator\\">=</span>d_model<span class=\\"token punctuation\\">,</span> n_head<span class=\\"token operator\\">=</span>n_head<span class=\\"token punctuation\\">)</span>\\n        <span class=\\"token keyword\\">elif</span> pe <span class=\\"token operator\\">==</span> <span class=\\"token string\\">'relative'</span><span class=\\"token punctuation\\">:</span>\\n            self<span class=\\"token punctuation\\">.</span>attention <span class=\\"token operator\\">=</span> RPEMultiHeadAttention<span class=\\"token punctuation\\">(</span>d_model<span class=\\"token operator\\">=</span>d_model<span class=\\"token punctuation\\">,</span> n_head<span class=\\"token operator\\">=</span>n_head<span class=\\"token punctuation\\">)</span>\\n        <span class=\\"token keyword\\">else</span><span class=\\"token punctuation\\">:</span>\\n            self<span class=\\"token punctuation\\">.</span>attention <span class=\\"token operator\\">=</span> MultiHeadAttention<span class=\\"token punctuation\\">(</span>d_model<span class=\\"token operator\\">=</span>d_model<span class=\\"token punctuation\\">,</span> n_head<span class=\\"token operator\\">=</span>n_head<span class=\\"token punctuation\\">,</span> pe<span class=\\"token operator\\">=</span><span class=\\"token boolean\\">False</span><span class=\\"token punctuation\\">)</span>\\n        self<span class=\\"token punctuation\\">.</span>dropout1 <span class=\\"token operator\\">=</span> nn<span class=\\"token punctuation\\">.</span>Dropout<span class=\\"token punctuation\\">(</span>p<span class=\\"token operator\\">=</span>drop_prob<span class=\\"token punctuation\\">)</span>\\n        self<span class=\\"token punctuation\\">.</span>ffn <span class=\\"token operator\\">=</span> PositionWiseFeedForward<span class=\\"token punctuation\\">(</span>d_model<span class=\\"token operator\\">=</span>d_model<span class=\\"token punctuation\\">,</span> hidden<span class=\\"token operator\\">=</span>ffn_hidden<span class=\\"token punctuation\\">,</span> drop_prob<span class=\\"token operator\\">=</span>drop_prob<span class=\\"token punctuation\\">)</span>\\n        self<span class=\\"token punctuation\\">.</span>dropout2 <span class=\\"token operator\\">=</span> nn<span class=\\"token punctuation\\">.</span>Dropout<span class=\\"token punctuation\\">(</span>p<span class=\\"token operator\\">=</span>drop_prob<span class=\\"token punctuation\\">)</span>\\n        self<span class=\\"token punctuation\\">.</span>norm_type <span class=\\"token operator\\">=</span> norm_type  <span class=\\"token comment\\"># post, pre, or rezero</span>\\n        <span class=\\"token keyword\\">if</span> self<span class=\\"token punctuation\\">.</span>norm_type <span class=\\"token operator\\">==</span> <span class=\\"token string\\">'pre'</span> <span class=\\"token keyword\\">or</span> self<span class=\\"token punctuation\\">.</span>norm_type <span class=\\"token operator\\">==</span> <span class=\\"token string\\">'post'</span><span class=\\"token punctuation\\">:</span>\\n            self<span class=\\"token punctuation\\">.</span>norm1 <span class=\\"token operator\\">=</span> LayerNorm<span class=\\"token punctuation\\">(</span>d_model<span class=\\"token operator\\">=</span>d_model<span class=\\"token punctuation\\">,</span> bias<span class=\\"token operator\\">=</span>norm_bias<span class=\\"token punctuation\\">)</span>\\n            self<span class=\\"token punctuation\\">.</span>norm2 <span class=\\"token operator\\">=</span> LayerNorm<span class=\\"token punctuation\\">(</span>d_model<span class=\\"token operator\\">=</span>d_model<span class=\\"token punctuation\\">,</span> bias<span class=\\"token operator\\">=</span>norm_bias<span class=\\"token punctuation\\">)</span>\\n        <span class=\\"token keyword\\">else</span><span class=\\"token punctuation\\">:</span>\\n            self<span class=\\"token punctuation\\">.</span>res_weight <span class=\\"token operator\\">=</span> nn<span class=\\"token punctuation\\">.</span>Parameter<span class=\\"token punctuation\\">(</span>torch<span class=\\"token punctuation\\">.</span>Tensor<span class=\\"token punctuation\\">(</span><span class=\\"token punctuation\\">[</span><span class=\\"token number\\">0</span><span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">,</span> requires_grad<span class=\\"token operator\\">=</span><span class=\\"token boolean\\">True</span><span class=\\"token punctuation\\">)</span>\\n\\n    <span class=\\"token keyword\\">def</span> <span class=\\"token function\\">forward</span><span class=\\"token punctuation\\">(</span>self<span class=\\"token punctuation\\">,</span> x<span class=\\"token punctuation\\">,</span> src_mask<span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">:</span>\\n        <span class=\\"token keyword\\">if</span> self<span class=\\"token punctuation\\">.</span>norm_type <span class=\\"token operator\\">==</span> <span class=\\"token string\\">'post'</span><span class=\\"token punctuation\\">:</span>\\n            x <span class=\\"token operator\\">=</span> self<span class=\\"token punctuation\\">.</span>norm1<span class=\\"token punctuation\\">(</span>self<span class=\\"token punctuation\\">.</span>dropout1<span class=\\"token punctuation\\">(</span>self<span class=\\"token punctuation\\">.</span>attention<span class=\\"token punctuation\\">(</span>query<span class=\\"token operator\\">=</span>x<span class=\\"token punctuation\\">,</span> key<span class=\\"token operator\\">=</span>x<span class=\\"token punctuation\\">,</span> value<span class=\\"token operator\\">=</span>x<span class=\\"token punctuation\\">,</span> mask<span class=\\"token operator\\">=</span>src_mask<span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">)</span> <span class=\\"token operator\\">+</span> x<span class=\\"token punctuation\\">)</span>\\n            x <span class=\\"token operator\\">=</span> self<span class=\\"token punctuation\\">.</span>norm2<span class=\\"token punctuation\\">(</span>self<span class=\\"token punctuation\\">.</span>dropout2<span class=\\"token punctuation\\">(</span>self<span class=\\"token punctuation\\">.</span>ffn<span class=\\"token punctuation\\">(</span>x<span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">)</span> <span class=\\"token operator\\">+</span> x<span class=\\"token punctuation\\">)</span>\\n        <span class=\\"token keyword\\">elif</span> self<span class=\\"token punctuation\\">.</span>norm_type <span class=\\"token operator\\">==</span> <span class=\\"token string\\">'pre'</span><span class=\\"token punctuation\\">:</span>\\n            x_pre_norm <span class=\\"token operator\\">=</span> self<span class=\\"token punctuation\\">.</span>norm1<span class=\\"token punctuation\\">(</span>x<span class=\\"token punctuation\\">)</span>\\n            x <span class=\\"token operator\\">=</span> self<span class=\\"token punctuation\\">.</span>dropout1<span class=\\"token punctuation\\">(</span>self<span class=\\"token punctuation\\">.</span>attention<span class=\\"token punctuation\\">(</span>query<span class=\\"token operator\\">=</span>x_pre_norm<span class=\\"token punctuation\\">,</span> key<span class=\\"token operator\\">=</span>x_pre_norm<span class=\\"token punctuation\\">,</span> value<span class=\\"token operator\\">=</span>x_pre_norm<span class=\\"token punctuation\\">,</span> mask<span class=\\"token operator\\">=</span>src_mask<span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">)</span> <span class=\\"token operator\\">+</span> x\\n            x <span class=\\"token operator\\">=</span> self<span class=\\"token punctuation\\">.</span>dropout2<span class=\\"token punctuation\\">(</span>self<span class=\\"token punctuation\\">.</span>ffn<span class=\\"token punctuation\\">(</span>self<span class=\\"token punctuation\\">.</span>norm2<span class=\\"token punctuation\\">(</span>x<span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">)</span> <span class=\\"token operator\\">+</span> x\\n            <span class=\\"token comment\\"># x = self.attention(query=x_pre_norm, key=x_pre_norm, value=x_pre_norm, mask=src_mask) + x</span>\\n            <span class=\\"token comment\\"># x = self.ffn(self.norm2(x)) + x</span>\\n        <span class=\\"token keyword\\">else</span><span class=\\"token punctuation\\">:</span>\\n            x <span class=\\"token operator\\">=</span> self<span class=\\"token punctuation\\">.</span>dropout1<span class=\\"token punctuation\\">(</span>self<span class=\\"token punctuation\\">.</span>attention<span class=\\"token punctuation\\">(</span>query<span class=\\"token operator\\">=</span>x<span class=\\"token punctuation\\">,</span> key<span class=\\"token operator\\">=</span>x<span class=\\"token punctuation\\">,</span> value<span class=\\"token operator\\">=</span>x<span class=\\"token punctuation\\">,</span> mask<span class=\\"token operator\\">=</span>src_mask<span class=\\"token punctuation\\">)</span> <span class=\\"token operator\\">*</span> self<span class=\\"token punctuation\\">.</span>res_weight<span class=\\"token punctuation\\">)</span> <span class=\\"token operator\\">+</span> x\\n            x <span class=\\"token operator\\">=</span> self<span class=\\"token punctuation\\">.</span>dropout2<span class=\\"token punctuation\\">(</span>self<span class=\\"token punctuation\\">.</span>ffn<span class=\\"token punctuation\\">(</span>x<span class=\\"token punctuation\\">)</span> <span class=\\"token operator\\">*</span> self<span class=\\"token punctuation\\">.</span>res_weight<span class=\\"token punctuation\\">)</span> <span class=\\"token operator\\">+</span> x\\n        <span class=\\"token keyword\\">return</span> x\\n        <span class=\\"token comment\\"># 输出给encoder的x的shape（batch_size,seq_len,embed_size）</span>\\n</code></pre></div>","autoDesc":true}`);export{k as comp,d as data};
